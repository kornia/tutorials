{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fb3a3e",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/extract-combine-patches.ipynb)\n",
    "\n",
    "# Extracting and Combining Tensor Patches\n",
    "\n",
    "In this tutorial we will show how you can extract and combine tensor patches using kornia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c3683",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611b350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/kornia/kornia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4bd6d",
   "metadata": {},
   "source": [
    "## Using Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7419ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 8, 8])\n",
      "torch.Size([2, 9, 3, 4, 4])\n",
      "torch.Size([2, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from kornia.contrib import CombineTensorPatches, ExtractTensorPatches\n",
    "\n",
    "h, w = 8, 8\n",
    "win = 4\n",
    "pad = 2\n",
    "\n",
    "image = torch.randn(2, 3, h, w)\n",
    "print(image.shape)\n",
    "tiler = ExtractTensorPatches(window_size=win, stride=win, padding=pad)\n",
    "merger = CombineTensorPatches(original_size=(h, w), window_size=win,  unpadding=pad)\n",
    "image_tiles = tiler(image)\n",
    "print(image_tiles.shape)\n",
    "new_image = merger(image_tiles)\n",
    "print(new_image.shape)\n",
    "assert (image == new_image).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e9bd7e",
   "metadata": {},
   "source": [
    "## Using Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad0bae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 8])\n",
      "torch.Size([1, 9, 1, 4, 4])\n",
      "torch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from kornia.contrib import combine_tensor_patches, extract_tensor_patches\n",
    "\n",
    "h, w = 8, 8\n",
    "win = 4\n",
    "pad = 2\n",
    "\n",
    "image = torch.randn(1, 1, h, w)\n",
    "print(image.shape)\n",
    "patches = extract_tensor_patches(image, window_size=win, stride=win, padding=pad)\n",
    "print(patches.shape)\n",
    "restored_img = combine_tensor_patches(patches, original_size=(h, w), window_size=win,  stride=win, unpadding=pad)\n",
    "print(restored_img.shape)\n",
    "assert (image == restored_img).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fb037",
   "metadata": {},
   "source": [
    "While using these functions, it is important to keep track of the following points:\n",
    "\n",
    "1. Image after padding must be divisible by window_size \n",
    "2. CombineTensorPatches only works with stride == window_size (PRs are welcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d12d26",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9cdb8",
   "metadata": {},
   "source": [
    "All parameters of extract and combine functions accept a **single int** or **tuple of two ints**. Padding (for extract) and unpadding (for combine) also accept a **tuple of four ints**. Since padding is an integral part of these functions, it's important to note the following:\n",
    "\n",
    "- If padding is `p` -> it means both height and width are padded by `2*p`\n",
    "- If padding is `(ph, pw)` -> it means height is padded by `2*ph` and width is padded by `2*pw` \n",
    "- If padding is `(p1, p2, p3, p4)` -> it means image is padded by `p1` at the top, by `p2` at the bottom, by `p3` on the left, and by `p4` on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5026e",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01add821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_combine(image, window_size, padding):\n",
    "    h, w = image.shape[-2:]\n",
    "    tiler = ExtractTensorPatches(window_size=window_size, stride=window_size, padding=padding)\n",
    "    merger = CombineTensorPatches(original_size=(h, w), window_size=window_size, unpadding=padding)\n",
    "    image_tiles = tiler(image)\n",
    "    print(f\"Shape of tensor patches = {image_tiles.shape}\")\n",
    "    merged_image = merger(image_tiles)\n",
    "    print(f\"Shape of merged image = {merged_image.shape}\")\n",
    "    assert (image == merged_image).all()\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c9c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor patches = torch.Size([2, 9, 3, 4, 4])\n",
      "Shape of merged image = torch.Size([2, 3, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "image = torch.randn(2, 3, 9, 9)\n",
    "_ = extract_and_combine(image, window_size=(4, 4), padding=(2, 1, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2d65a",
   "metadata": {},
   "source": [
    "Why is padding = (2, 1, 2, 1)?\n",
    "\n",
    "Recall that we need to ensure the padded image is divisible by `window_size`. The image is of size `(9, 9)` and `window_size` = `(4, 4)`, so we need to pad it by 3 units. In the cell above we padded the top by 2, bottom by 1, left by 2 and right by 1 i.e. `padding = (2, 1, 2, 1)`. You could have also used `padding = (1, 2, 1, 2)` to achieve the same result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9529ffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor patches = torch.Size([2, 9, 3, 4, 4])\n",
      "Shape of merged image = torch.Size([2, 3, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "image = torch.randn(2, 3, 9, 9)\n",
    "_ = extract_and_combine(image, window_size=(4, 4), padding=(1, 2, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62976aa7",
   "metadata": {},
   "source": [
    "These functions also work with rectangular images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65659e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "rect_image = torch.randn(1, 1, 8, 6)\n",
    "print(rect_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95f3da",
   "metadata": {},
   "source": [
    "If we use the same `window_size = (4,4)`, we can see that the height (8) is already divisible by `window_size` but this is not the case for width (6). To fix this, we just need to pad the width dimension by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a07b557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor patches = torch.Size([1, 4, 1, 4, 4])\n",
      "Shape of merged image = torch.Size([1, 1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "restored_image = extract_and_combine(rect_image, window_size=(4,4), padding=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb44a8",
   "metadata": {},
   "source": [
    "Recall that when padding is a tuple of ints `(ph, pw)`, the height and width are padded by `2*ph` and `2*pw` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7997ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the original image and restored image are the same\n",
    "assert (restored_image == rect_image).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
